{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgHqrkeat2r62SxJNTIIaa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/macorony/ConvNet_Examples/blob/main/GoogLeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "credit resource: https://www.youtube.com/watch?v=uQc4Fs7yx5I"
      ],
      "metadata": {
        "id": "Dc5KOhwlW8_o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cnh0Y2pwW0Km"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define convolution block with different kernels\n",
        "class conv_block(nn.Module):\n",
        "  def __init__(self, in_channel, out_channel, **kwargs):\n",
        "    super(conv_block, self).__init__()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv = nn.Conv2d(in_channel, out_channel, **kwargs)\n",
        "    self.batchnorm = nn.BatchNorm2d(out_channel)\n",
        "  def forward(self, x):\n",
        "    return self.relu(self.batchnorm(self.conv(x)))"
      ],
      "metadata": {
        "id": "cFD8gGSFXE4c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define inception block\n",
        "class Inception_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_1x1, out_3x3_reduce, out_3x3, out_5x5_reduce, out_5x5, out_pool):\n",
        "    super(Inception_block, self).__init__()\n",
        "    # 1x1 convolution\n",
        "    self.branch1 = nn.Conv2d(in_channels, out_1x1, kernel_size=1)\n",
        "    # 1x1 -> 3x3 convolution\n",
        "    self.branch2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_3x3_reduce, kernel_size=1),\n",
        "        nn.Conv2d(out_3x3_reduce, out_3x3, kernel_size=3, padding=1)\n",
        "    )\n",
        "    # 1x1 -> 5x5 convolution\n",
        "    self.branch3 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_5x5_reduce, kernel_size=1),\n",
        "        nn.Conv2d(out_5x5_reduce, out_5x5, kernel_size=5, padding=2)\n",
        "    )\n",
        "    # 3x3 max pooling -> 1x1 convolution\n",
        "    self.branch4 = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "        nn.Conv2d(in_channels, out_pool, kernel_size=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    branch1 = self.branch1(x)\n",
        "    branch2 = self.branch2(x)\n",
        "    branch3 = self.branch3(x)\n",
        "    branch4 = self.branch4(x)\n",
        "\n",
        "    outputs = [branch1, branch2, branch3, branch4]\n",
        "    return torch.cat(outputs, 1)"
      ],
      "metadata": {
        "id": "5u9rTLafY7LF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define GoogLeNet\n",
        "class GoogLeNet(nn.Module):\n",
        "  def __init__(self, num_classes=100):\n",
        "    super(GoogLeNet, self).__init__()\n",
        "    # initial layer\n",
        "    self.pre_layers = nn.Sequential(\n",
        "        nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
        "        nn.MaxPool2d(3, stride=2, padding=1),\n",
        "        nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
        "        nn.MaxPool2d(3, stride=2, padding=1)\n",
        "    )\n",
        "    # inception block\n",
        "    self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\n",
        "    self.inception3b = Inception_block(256, 128, 128, 192, 32,96, 64)\n",
        "    self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "    self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\n",
        "    self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\n",
        "    self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\n",
        "    self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\n",
        "    self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128)\n",
        "\n",
        "    self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\n",
        "    self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "    # final layers\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pre_layers(x)\n",
        "    x = self.inception3a(x)\n",
        "    x = self.inception3b(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.inception4a(x)\n",
        "    x = self.inception4b(x)\n",
        "    x = self.inception4c(x)\n",
        "    x = self.inception4d(x)\n",
        "    x = self.inception4e(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.inception5a(x)\n",
        "    x = self.inception5b(x)\n",
        "\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "6mg441mgkXSn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize((0.1307),(0.3081))\n",
        "    ]\n",
        "    )"
      ],
      "metadata": {
        "id": "zDMellChNA92"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.FashionMNIST('./fashion', train=True, transform=transform, download=True)\n",
        "test_set = torchvision.datasets.FashionMNIST('./fashion', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "yM4a7VvossiV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=10, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=10, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "FJsBi2E9NqL7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GoogLeNet(num_classes=10)"
      ],
      "metadata": {
        "id": "yrdzmSnkNnXT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fc = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "KMK9yZ5lT_Ed"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_training(loader, nnModel, EPOCH, optimizer, loss_function):\n",
        "  nnModel.train()\n",
        "  for epoch in range(EPOCH):\n",
        "    print(f'Start to train the epoch {epoch+1}.')\n",
        "    running_loss = 0\n",
        "    for i, data in enumerate(loader):\n",
        "      inputs, labels = data\n",
        "      optimizer.zero_grad()\n",
        "      outputs = nnModel(inputs)\n",
        "      loss = loss_function(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss\n",
        "      if i % 1000 == 999:\n",
        "        print(f\"At {i+1}th batch the loss is {running_loss}.\")\n",
        "        running_loss = 0\n",
        "  print('Finish the training.')"
      ],
      "metadata": {
        "id": "hP19mmuOVRN0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wlu7m9l6XJ7c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}